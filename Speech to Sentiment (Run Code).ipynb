{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "641aaa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_glove_embeddings(filepath):\n",
    "    embeddings_index = {}\n",
    "    with open(filepath, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    return embeddings_index\n",
    "\n",
    "# Load GloVe embeddings\n",
    "glove_file = 'glove.6B.100d.txt'\n",
    "embeddings_index = load_glove_embeddings(glove_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80da2426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = tf.keras.models.load_model('Model.h5', compile=False)\n",
    "\n",
    "# Initialize label encoder with class labels\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.classes_ = np.array(['negative', 'neutral', 'positive'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e86ebc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import speech_recognition as sr\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "def record_sentence(filename='output.wav', duration=5, samplerate=16000):\n",
    "    print(\"Recording...\")\n",
    "    recording = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=1, dtype='int16')\n",
    "    sd.wait()\n",
    "    write(filename, samplerate, recording)\n",
    "    print(\"Recording complete. File saved as\", filename)\n",
    "\n",
    "def audio_to_text(filename='output.wav'):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(filename) as source:\n",
    "        audio = recognizer.record(source)\n",
    "    return recognizer.recognize_google(audio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4390ecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9_]+', '', text)  # Remove mentions starting with @\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)    # Remove non-alphanumeric characters\n",
    "    text = text.lower()                        # Convert to lowercase\n",
    "    return text\n",
    "\n",
    "# Vectorize text using GloVe embeddings\n",
    "def vectorize_text_with_glove(text, embeddings_index):\n",
    "    words = text.split()\n",
    "    embedding_dim = len(next(iter(embeddings_index.values())))\n",
    "    text_vector = np.zeros(embedding_dim)\n",
    "    count = 0\n",
    "    for word in words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            text_vector += embedding_vector\n",
    "            count += 1\n",
    "    if count != 0:\n",
    "        text_vector /= count\n",
    "    return text_vector\n",
    "\n",
    "def predict_sentiment(text, embeddings_index, model, label_encoder):\n",
    "    # Preprocess and vectorize text\n",
    "    preprocessed_text = preprocess_text(text)\n",
    "    text_vector = vectorize_text_with_glove(preprocessed_text, embeddings_index)\n",
    "\n",
    "    # Reshape for model input (timesteps, features)\n",
    "    text_vector_reshaped = text_vector.reshape((1, 1, len(text_vector)))\n",
    "\n",
    "    # Predict sentiment\n",
    "    pred_probs = model.predict(text_vector_reshaped)\n",
    "    pred_label_index = np.argmax(pred_probs, axis=1)\n",
    "    pred_label = label_encoder.inverse_transform(pred_label_index)\n",
    "\n",
    "    return pred_label[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96441d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording complete. File saved as output.wav\n"
     ]
    },
    {
     "ename": "UnknownValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownValueError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m record_sentence()  \u001b[38;5;66;03m# Record audio\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Convert audio to text\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m text \u001b[38;5;241m=\u001b[39m audio_to_text()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecognized text:\u001b[39m\u001b[38;5;124m\"\u001b[39m, text)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Predict sentiment\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 16\u001b[0m, in \u001b[0;36maudio_to_text\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sr\u001b[38;5;241m.\u001b[39mAudioFile(filename) \u001b[38;5;28;01mas\u001b[39;00m source:\n\u001b[0;32m     15\u001b[0m     audio \u001b[38;5;241m=\u001b[39m recognizer\u001b[38;5;241m.\u001b[39mrecord(source)\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m recognizer\u001b[38;5;241m.\u001b[39mrecognize_google(audio)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\speech_recognition\\recognizers\\google.py:263\u001b[0m, in \u001b[0;36mrecognize_legacy\u001b[1;34m(recognizer, audio_data, key, language, pfilter, show_all, with_confidence, endpoint)\u001b[0m\n\u001b[0;32m    256\u001b[0m response_text \u001b[38;5;241m=\u001b[39m obtain_transcription(\n\u001b[0;32m    257\u001b[0m     request, timeout\u001b[38;5;241m=\u001b[39mrecognizer\u001b[38;5;241m.\u001b[39moperation_timeout\n\u001b[0;32m    258\u001b[0m )\n\u001b[0;32m    260\u001b[0m output_parser \u001b[38;5;241m=\u001b[39m OutputParser(\n\u001b[0;32m    261\u001b[0m     show_all\u001b[38;5;241m=\u001b[39mshow_all, with_confidence\u001b[38;5;241m=\u001b[39mwith_confidence\n\u001b[0;32m    262\u001b[0m )\n\u001b[1;32m--> 263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output_parser\u001b[38;5;241m.\u001b[39mparse(response_text)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\speech_recognition\\recognizers\\google.py:134\u001b[0m, in \u001b[0;36mOutputParser.parse\u001b[1;34m(self, response_text)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, response_text: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 134\u001b[0m     actual_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_to_result(response_text)\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshow_all:\n\u001b[0;32m    136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m actual_result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\speech_recognition\\recognizers\\google.py:183\u001b[0m, in \u001b[0;36mOutputParser.convert_to_result\u001b[1;34m(response_text)\u001b[0m\n\u001b[0;32m    181\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m UnknownValueError()\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 183\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnknownValueError()\n",
      "\u001b[1;31mUnknownValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load GloVe embeddings\n",
    "glove_file = 'glove.6B.100d.txt'\n",
    "embeddings_index = load_glove_embeddings(glove_file)\n",
    "\n",
    "# Load model and label encoder\n",
    "model = tf.keras.models.load_model('Model.h5', compile=False)\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.classes_ = np.array(['negative', 'neutral', 'positive'])\n",
    "\n",
    "# Record and process a single sentence\n",
    "record_sentence()  # Record audio\n",
    "\n",
    "# Convert audio to text\n",
    "text = audio_to_text()\n",
    "print(\"Recognized text:\", text)\n",
    "\n",
    "# Predict sentiment\n",
    "predicted_sentiment = predict_sentiment(text, embeddings_index, model, label_encoder)\n",
    "print(\"Predicted sentiment:\", predicted_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19281fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
